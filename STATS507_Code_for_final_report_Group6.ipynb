{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "STATS507_Code_for_final_report_Group6.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3I2hlNAbzHOj"
      },
      "source": [
        "# **507 final project**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h5tkw2capO9r"
      },
      "source": [
        "First, save the data on google drive and mount to google drive, so we can use the data in colab."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HX5fM_9MmmfO"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "duJC9iUUmvxe"
      },
      "source": [
        "%cp -r 'drive/My Drive/507_project/plant2/.' train"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LWr-tqXDlU9S"
      },
      "source": [
        "from PIL import Image\n",
        "\n",
        "import random\n",
        "from matplotlib import pyplot as plt\n",
        "from os import listdir, path\n",
        "import os\n",
        "\n",
        "from torch import nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from glob import glob\n",
        "import torch\n",
        "import numpy as np\n",
        "from torchvision.transforms.transforms import Compose, Resize, ToTensor, CenterCrop\n",
        "import time\n",
        "import pandas as pd\n",
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "from timeit import default_timer as timer\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "import random\n",
        "import skimage\n",
        "from skimage import io\n",
        "from skimage.transform import rotate, AffineTransform, warp\n",
        "from skimage import util\n",
        "from skimage.filters import gaussian\n",
        "from skimage import img_as_ubyte\n",
        "from torchsummary import summary\n",
        "from torchvision import datasets, transforms,models\n",
        "from torch.optim import lr_scheduler\n",
        "from imblearn.over_sampling import SMOTE"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MhK-5ILtz90D"
      },
      "source": [
        "Implement data pre-precessing and split the data into train, test, valid datasets randomly."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qK4D_AEaldRL"
      },
      "source": [
        "def createdir(root_dir, target_dir):\n",
        "    all_labels = listdir(path.join(root_dir, 'train'))\n",
        "    all_data = []\n",
        "    \n",
        "    # Create a list of tuples out of data samples. Each tuple includes images file name and an int as label code\n",
        "    for label_code, parent_dir in enumerate(all_labels):\n",
        "        os.makedirs(path.join(target_dir, parent_dir))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OHDPr2p-ldTX"
      },
      "source": [
        "createdir('.','./new/train')\n",
        "createdir('.','./new/test')\n",
        "createdir('.','./new/valid')\n",
        "createdir('.','./new/origin_train')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LejZGuL2lcxk"
      },
      "source": [
        "IMG_SIZE = 256\n",
        "IMG_SIZE1 = 224"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nig19dKyldVM"
      },
      "source": [
        "new_colormin=(25,50,50)\n",
        "new_colormax=(80,255,255)\n",
        "\n",
        "def plot_mask(image, colormin, colormax):\n",
        "        hsv_p1 = cv2.cvtColor(image, cv2.COLOR_RGB2HSV)   #R, G, and B are converted to the floating-point format and scaled to fit the 0 to 1 range\n",
        "        mask = cv2.inRange(hsv_p1, colormin , colormax)  #?\n",
        "        result = cv2.bitwise_and(image, image, mask=mask)\n",
        "        return result\n",
        "\n",
        "\n",
        "def rotate(image, angle=90, scale=1.0):\n",
        "    '''\n",
        "    Rotate the image\n",
        "    :param image: image to be processed\n",
        "    :param angle: Rotation angle in degrees. Positive values mean counter-clockwise rotation (the coordinate origin is assumed to be the top-left corner).\n",
        "    :param scale: Isotropic scale factor.\n",
        "    '''\n",
        "    w = image.shape[1]\n",
        "    h = image.shape[0]\n",
        "    #rotate matrix\n",
        "    M = cv2.getRotationMatrix2D((w/2,h/2), angle, scale)\n",
        "    #rotate\n",
        "    image = cv2.warpAffine(image,M,(w,h))\n",
        "    return image\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nbk3xCNHldZX"
      },
      "source": [
        "def split_train_test(root_dir, train_dir, val_dir, test_dir, origin_train_dir):\n",
        "    all_labels = listdir(path.join(root_dir, 'train'))\n",
        "    all_data = []\n",
        "    target_size = 1500\n",
        "    # Create a list of tuples out of data samples. Each tuple includes images file name and an int as label code\n",
        "    for label_code, parent_dir in enumerate(all_labels):\n",
        "        name_list = []\n",
        "        parent_directory = path.join(root_dir, 'train', parent_dir)\n",
        "        file_list = listdir(parent_directory)\n",
        "        random.shuffle(file_list)\n",
        "        for test_sample in file_list[:40]:\n",
        "            img = cv2.imread(path.join(parent_directory, test_sample))\n",
        "            img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "            img = plot_mask(img, new_colormin, new_colormax)\n",
        "\n",
        "            cv2.imwrite(path.join(test_dir, parent_dir, test_sample), img)\n",
        "        for val_sample in file_list[40:80]:\n",
        "            img = cv2.imread(path.join(parent_directory, val_sample))\n",
        "            img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "            img = plot_mask(img, new_colormin, new_colormax)\n",
        "\n",
        "            cv2.imwrite(path.join(val_dir, parent_dir, val_sample), img)\n",
        "        origin_size = len(file_list) - 80\n",
        "        choose = min(int((target_size - origin_size)/3), origin_size)\n",
        "        for addi in file_list[80:80+choose]:\n",
        "            angle = np.random.uniform(45,180,1)\n",
        "            scale = np.random.uniform(0.8,1.2,1)\n",
        "            img = cv2.imread(path.join(parent_directory, addi))\n",
        "            img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "            img = plot_mask(img, new_colormin, new_colormax)\n",
        "\n",
        "            flipped_img = np.fliplr(img)\n",
        "            flipped_img2 = np.flipud(img)\n",
        "            rotated_img = rotate(img, angle=angle, scale=scale)\n",
        "            #noised_img = skimage.util.random_noise(img, mode=\"poisson\")\n",
        "            cv2.imwrite(path.join(train_dir, parent_dir, addi), img)\n",
        "            cv2.imwrite(path.join(origin_train_dir, parent_dir, addi), img)\n",
        "\n",
        "            cv2.imwrite(path.join(train_dir, parent_dir, addi[:len(addi)-4]+\"_flip.png\"), flipped_img)\n",
        "            cv2.imwrite(path.join(train_dir, parent_dir, addi[:len(addi)-4]+\"_flipud.png\"), flipped_img2)\n",
        "            cv2.imwrite(path.join(train_dir, parent_dir, addi[:len(addi)-4]+\"_rotate.png\"), rotated_img)\n",
        "            #io.imsave(path.join(train_dir, parent_dir, addi[:len(addi)-4]+\"_noise.png\"), img_as_ubyte(noised_img))\n",
        "        for rest in file_list[80+choose:]:\n",
        "            img = cv2.imread(path.join(parent_directory, rest))\n",
        "            img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "            img = plot_mask(img, new_colormin, new_colormax)\n",
        "\n",
        "            cv2.imwrite(path.join(origin_train_dir, parent_dir, rest), img)\n",
        "            cv2.imwrite(path.join(train_dir, parent_dir, rest), img)\n",
        "\n",
        "        if 4*origin_size < target_size:\n",
        "            choose2 = min(int(target_size-4*origin_size), origin_size)\n",
        "            for add2 in file_list[80:80+choose2]:\n",
        "                angle = np.random.uniform(45,180,1)\n",
        "                scale = np.random.uniform(0.8,1.2,1)\n",
        "                img = cv2.imread(path.join(parent_directory, add2))\n",
        "                img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "                img = plot_mask(img, new_colormin, new_colormax)\n",
        "                rotated_img2 = rotate(img, angle=angle, scale=scale)\n",
        "                cv2.imwrite(path.join(train_dir, parent_dir, add2[:len(add2)-4]+\"_rotate2.png\"), rotated_img2)\n",
        "\n",
        "        if 5*origin_size < target_size:\n",
        "            choose3 = min(int(target_size-5*origin_size), origin_size)\n",
        "            for add3 in file_list[80:80+choose3]:\n",
        "                angle = np.random.uniform(45,180,1)\n",
        "                scale = np.random.uniform(0.8,1.2,1)\n",
        "                img = cv2.imread(path.join(parent_directory, add3))\n",
        "                img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "                img = plot_mask(img, new_colormin, new_colormax)\n",
        "                rotated_img3 = rotate(img, angle=angle, scale=scale)\n",
        "                cv2.imwrite(path.join(train_dir, parent_dir, add3[:len(add3)-4]+\"_rotate3.png\"), rotated_img3)\n",
        "\n",
        "        if 6*origin_size < target_size:\n",
        "            choose4 = min(int(target_size-6*origin_size), origin_size)\n",
        "            for add4 in file_list[80:80+choose4]:\n",
        "                angle = np.random.uniform(45,180,1)\n",
        "                scale = np.random.uniform(0.8,1.2,1)\n",
        "                img = cv2.imread(path.join(parent_directory, add4))\n",
        "                img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "                img = plot_mask(img, new_colormin, new_colormax)\n",
        "                rotated_img4 = rotate(img, angle=angle, scale=scale)\n",
        "                cv2.imwrite(path.join(train_dir, parent_dir, add4[:len(add4)-4]+\"_rotate4.png\"), rotated_img4)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7AtqDh2Oldba"
      },
      "source": [
        "split_train_test('.', './new/train','./new/valid', './new/test', './new/origin_train')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "moOTxHNRldXr"
      },
      "source": [
        "def getDataLoaders_split(train_dir, train_transforms, batch_size):\n",
        "    all_labels = listdir(train_dir)\n",
        "    all_data = []\n",
        "    for label_code, parent_dir in enumerate(all_labels):\n",
        "        this_dir_images = glob(path.join(train_dir, parent_dir, '*.png'))\n",
        "        all_data += zip(this_dir_images, [label_code]*len(this_dir_images))\n",
        "    random.shuffle(all_data)\n",
        "    train_data = SeedlingDataset(all_data, len(all_labels), transform=train_transforms)\n",
        "    train_loader = DataLoader(train_data, batch_size=batch_size, shuffle=True, num_workers=0)\n",
        "    return train_loader"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_nqfqa5O0K0K"
      },
      "source": [
        "The first model we use is a 4-layer CNN model. We bulid the model and train it."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ChAYsUCfl5_2"
      },
      "source": [
        "class TinyModel(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(TinyModel, self).__init__()\n",
        "        self.conv1 = nn.Sequential(nn.Conv2d(3, 12, kernel_size = 5, stride = 1,padding = 2, bias = True), nn.BatchNorm2d(12), nn.ReLU())\n",
        "        self.conv2 = nn.Sequential(nn.Conv2d(12, 24, kernel_size = 5, stride = 1, bias = True), nn.BatchNorm2d(24), nn.ReLU())\n",
        "        self.conv3 = nn.Sequential(nn.Conv2d(24, 48, kernel_size = 5, stride = 1, bias = True), nn.BatchNorm2d(48), nn.ReLU())\n",
        "        self.conv4 = nn.Sequential(nn.Conv2d(48, 96, kernel_size = 5, stride = 1, bias = True), nn.BatchNorm2d(96), nn.ReLU())\n",
        "\n",
        "        self.fc1 = nn.Linear(in_features=9600, out_features=1200)\n",
        "        self.fc2 = nn.Linear(in_features=1200, out_features=128)\n",
        "        self.fc3 = nn.Linear(in_features=128, out_features=12)\n",
        "        self.pool=nn.MaxPool2d(2,stride=2)\n",
        "\n",
        "    def forward(self, x):\n",
        "        #print(x.shape) \n",
        "        x = self.pool(self.conv1(x))\n",
        "        x = self.pool(self.conv2(x))\n",
        "        x = self.pool(self.conv3(x))\n",
        "        x = self.pool(self.conv4(x))\n",
        "        # print(x.shape)\n",
        "        x = x.view(x.size(0), -1)\n",
        "        #print(x.shape)\n",
        "        x = F.relu(self.fc1(x))\n",
        "        # print(x.shape)\n",
        "        x = F.relu(self.fc2(x))\n",
        "        x = F.relu(self.fc3(x))\n",
        "        return F.log_softmax(x, dim=1)\n",
        "\n",
        "    def loss(self, prediction, true_values):\n",
        "\n",
        "        return F.nll_loss(prediction, true_values)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G7NX2j99l9IE"
      },
      "source": [
        "# define a class for the dataset\n",
        "class SeedlingDataset(Dataset):\n",
        "    \n",
        "    def __init__(self, data, n_labels, transform=None):\n",
        "        \n",
        "        self.data = data\n",
        "        self.transform = transform\n",
        "        self.n_labels = n_labels\n",
        "        self.transform = transform\n",
        "        \n",
        "    def __len__(self):\n",
        "        \n",
        "        return len(self.data)\n",
        "    \n",
        "    def __getitem__(self, idx):\n",
        "        \n",
        "        data_file, image_code = self.data[idx]\n",
        "        img = Image.open(data_file)\n",
        "        img = img.convert('RGB')\n",
        "        if self.transform:\n",
        "            img = self.transform(img)\n",
        "        img = torch.from_numpy(np.array(img))\n",
        "        label = torch.tensor(image_code)\n",
        "        \n",
        "        return img, label\n",
        "    "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IC0Qxcn1l9Oy"
      },
      "source": [
        "def train(model, device, train_dataloader, optimizer, epoch, verbose=False):\n",
        "    \n",
        "    model.train()\n",
        "    total_loss = 0\n",
        "    for batch_idx, (image, label) in enumerate(train_dataloader):\n",
        "        \n",
        "        input_var = image.to(device)\n",
        "        target_var = label.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        output = model(input_var)\n",
        "        loss = model.loss(output, target_var)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        total_loss += loss\n",
        "        if batch_idx % 10 == 0 and verbose:\n",
        "            print('Train Epoch: {0}, Train batch: {1}, Batch loss: {2}'\n",
        "                  .format(epoch, batch_idx, loss))\n",
        "    \n",
        "    epoch_loss = total_loss/(batch_idx + 1)\n",
        "    \n",
        "    return epoch_loss\n",
        "    \n",
        "def valid(model, device, dataloader):\n",
        "    \n",
        "    model.eval()\n",
        "    total_loss = 0\n",
        "    with torch.no_grad():\n",
        "        for batch_idx, (image, label) in enumerate(dataloader):\n",
        "          input_var = image.to(device)\n",
        "          target_var = label.to(device)\n",
        "          output = model(input_var)\n",
        "          loss = model.loss(output, target_var)\n",
        "          total_loss += loss\n",
        "      \n",
        "        epoch_loss = total_loss/(batch_idx + 1)\n",
        "        # print('validation loss: ',epoch_loss)\n",
        "    return epoch_loss\n",
        "    \n",
        "def test(model, device, test_dataloader):\n",
        "    \n",
        "    model.eval()\n",
        "    correct = 0\n",
        "    with torch.no_grad():\n",
        "        for image, label in test_dataloader:\n",
        "            input_var = image.to(device)\n",
        "            target_var = label.to(device)\n",
        "            output = model(input_var)\n",
        "            prediction = output.argmax(dim=1, keepdim=True)\n",
        "            correct += prediction.eq(target_var.view_as(prediction)).sum().item()\n",
        "        accuracy = correct / len(test_dataloader.dataset)\n",
        "    \n",
        "    return accuracy"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gxeXdHb2l9TF"
      },
      "source": [
        "def AdjustLR(optim, lr):\n",
        "    '''\n",
        "    This is a simple hand-made function to decrease \n",
        "    optimizer's learning rate by a factor of 10 at a specific time\n",
        "    '''\n",
        "    for param_group in optim.param_groups:\n",
        "            param_group['lr'] /= 10"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HMiQCfpAmFxv"
      },
      "source": [
        "losses = []\n",
        "valid_losses = []\n",
        "accuracies = []\n",
        "test_accuracies = []\n",
        "n_epochs = 20\n",
        "learning_rate = 0.05\n",
        "lr_decay = 5 # every 10 epochs, the learning rate is divided by 10\n",
        "batch_size = 64\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)\n",
        "\n",
        "use_cuda = True # use True to switch to GPU\n",
        "\n",
        "device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
        "model = TinyModel().to(device)\n",
        "print('The model has {0} parameters'.format(sum([len(i.reshape(-1)) for i in model.parameters()]) ))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V9GRJ9lhmFz3"
      },
      "source": [
        "mean = [0.485, 0.456, 0.406]\n",
        "std = [0.229, 0.224, 0.225]\n",
        "\n",
        "mean1 = [0.5, 0.5, 0.5]\n",
        "std1 = [0.5, 0.5, 0.5]\n",
        "\n",
        "test_transform = Compose([Resize(IMG_SIZE), CenterCrop(IMG_SIZE1), ToTensor(), transforms.Normalize(mean, std)])\n",
        "train_transform = Compose([\n",
        "    transforms.RandomResizedCrop(size=IMG_SIZE, scale=(0.8, 1.0)),\n",
        "    transforms.RandomRotation(degrees=15),\n",
        "    transforms.CenterCrop(size=IMG_SIZE1),  # Image net standards\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean, std)  # Imagenet standards\n",
        "])\n",
        "\n",
        "# valid_data = SeedlingDataset(valid_data_filename, len(all_labels), transform=test_transform)\n",
        "valid_loader = getDataLoaders_split('./new/valid', test_transform, batch_size = batch_size)\n",
        "\n",
        "# train_data = SeedlingDataset(train_data_filename, len(all_labels), transform=train_transform)\n",
        "train_loader = getDataLoaders_split('./new/train', train_transform, batch_size = batch_size)\n",
        "\n",
        "# test_data = SeedlingDataset(test_data_filename, len(all_labels), transform=test_transform)\n",
        "test_loader = getDataLoaders_split('./new/test', test_transform, batch_size = batch_size)\n",
        "\n",
        "print('number of train examples: {0}, number of validation examples: {1}, number of test examples: {2}'\n",
        "      .format(len(train_loader.dataset), len(test_loader.dataset), len(test_loader.dataset)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4CIjQS12mF2k"
      },
      "source": [
        "for epoch in range(1, n_epochs + 1):\n",
        "    tic = time.time()\n",
        "    epoch_loss = train(model, device, train_loader, optimizer, epoch)\n",
        "    print('Training loss for epoch {0} is {1:.5f}'.format(epoch, epoch_loss))\n",
        "    losses.append(epoch_loss)\n",
        "    valid_loss = valid(model, device, valid_loader)\n",
        "    valid_losses.append(valid_loss)\n",
        "    print('Val loss: {0:.3f}'.format(valid_loss))\n",
        "    test_accuracy = test(model, device, test_loader)\n",
        "    print('Test accuracy: {0:.3f}'.format(test_accuracy))\n",
        "    test_accuracies.append(test_accuracy)\n",
        "    tac = time.time()\n",
        "    print('Epoch time: {0:0.1f} seconds'.format(tac - tic))\n",
        "    if epoch % lr_decay == 0:\n",
        "        AdjustLR(optimizer, learning_rate)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JaS6ofgIqfl4"
      },
      "source": [
        "Evaluate the 4-layer CNN model based on loss and accuracy plot; confusion matrix and f1 score."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jt57Bul5mF43"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "fig, ax1 = plt.subplots()\n",
        "\n",
        "step = np.arange(1,21, dtype = int)\n",
        "color = 'tab:red'\n",
        "ax1.set_xlabel('Epoch')\n",
        "ax1.set_ylabel('Average Cross Entropy', color=color)\n",
        "ax1.plot(step, losses, label=\"Train loss\")\n",
        "ax1.plot(step,valid_losses, label=\"Valid loss\")\n",
        "ax1.tick_params(axis='y', labelcolor=color)\n",
        "\n",
        "# ax2 = ax1.twinx()  # instantiate a second axes that shares the same x-axis\n",
        "\n",
        "# color = 'tab:blue'\n",
        "# ax2.set_ylabel('Accuracy', color=color)\n",
        "# # ax2.set_ylim(0,1)  # we already handled the x-label with ax1\n",
        "# ax2.plot(step, test_accuracies, color=\"g\", label = \"Test Accuracy\")\n",
        "# ax2.tick_params(axis='y', labelcolor=color)\n",
        "\n",
        "\n",
        "ax1.legend(loc=10)\n",
        "# ax2.legend(loc=7)\n",
        "plt.title('Validation& Training losses')\n",
        "# fig.tight_layout()  # otherwise the right y-label is slightly clipped\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bXwgA79zmdpO"
      },
      "source": [
        "from sklearn.metrics import f1_score, precision_score, recall_score\n",
        "\n",
        "# model.eval()\n",
        "# nb_classes = 12\n",
        "# confusion_matrix = torch.zeros(nb_classes, nb_classes)\n",
        "# with torch.no_grad():\n",
        "#     for i, (inputs, classes) in enumerate(test_loader):\n",
        "#         inputs = inputs.to(device)\n",
        "#         classes = classes.to(device)\n",
        "#         outputs = model(inputs)\n",
        "#         _, preds = torch.max(outputs, 1)\n",
        "#         for t, p in zip(classes.view(-1), preds.view(-1)):\n",
        "#             confusion_matrix[t.long(), p.long()] += 1\n",
        "# print(confusion_matrix)\n",
        "recall = confusion_matrix2.diag()/confusion_matrix2.sum(1) #recall\n",
        "precision = confusion_matrix2.diag()/confusion_matrix2.sum(0) #precision\n",
        "f1 = f1_score(classes.cpu().numpy(), preds.cpu().numpy(), average='macro')\n",
        "p = precision_score(classes.cpu().numpy(), preds.cpu().numpy(), average=\"macro\")\n",
        "r = recall_score(classes.cpu().numpy(), preds.cpu().numpy(), average=\"macro\")\n",
        "print(f1, p, r)\n",
        "confusion_matrix1 = torch.zeros(nb_classes, nb_classes)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7Gg0omHxmTnu"
      },
      "source": [
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "\n",
        "# CATEGORIES = ['Black-grass', 'Charlock', 'Cleavers', 'Common Chickweed', 'Common wheat', 'Fat Hen', 'Loose Silky-bent',\n",
        "#               'Maize', 'Scentless Mayweed', 'Shepherds Purse', 'Small-flowered Cranesbill', 'Sugar beet']\n",
        "\n",
        "# abbreviation = ['BG', 'Ch', 'Cl', 'CC', 'CW', 'FH', 'LSB', 'M', 'SM', 'SP', 'SFC', 'SB']\n",
        "CATEGORIES = ['Common Chickweed',\n",
        " 'Small-flowered Cranesbill',\n",
        " 'Maize',\n",
        " 'Loose Silky-bent',\n",
        " 'Black-grass',\n",
        " 'Common wheat',\n",
        " 'Scentless Mayweed',\n",
        " 'Cleavers',\n",
        " 'Charlock',\n",
        " 'ShepherdGÇÖs Purse',\n",
        " 'Fat Hen',\n",
        " 'Sugar beet']\n",
        "abbreviation = ['CC', 'SFC', 'M', 'LSB', 'BG', 'CW', 'SM', 'Cl', 'Ch', 'SP', 'FH', 'SB']\n",
        "pd.DataFrame({'class': CATEGORIES, 'abbreviation': abbreviation})\n",
        "fig, ax = plt.subplots(1)\n",
        "ax = sns.heatmap(confusion_matrix2, ax=ax, cmap=plt.cm.Blues, annot=True)\n",
        "ax.set_xticklabels(abbreviation)\n",
        "ax.set_yticklabels(abbreviation)\n",
        "plt.title('Confusion Matrix')\n",
        "plt.ylabel('True class')\n",
        "plt.xlabel('Predicted class')\n",
        "#fig.savefig('Confusion matrix.png', dpi=300)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_PFLKtGApb4g"
      },
      "source": [
        "Fit the pre-trained model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CIQDxRsgpgvs"
      },
      "source": [
        "drive.mount('/content/drive')\n",
        "path = \"/content/drive/My Drive/plant_seedlings_classification\"\n",
        "\n",
        "os.chdir(path)\n",
        "os.listdir(path)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qHK8oh2kIPAO"
      },
      "source": [
        "from torchvision import transforms\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from os import listdir, path\n",
        "import cv2\n",
        "from torchvision import datasets\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision import models\n",
        "import torch.nn as nn\n",
        "from torch import optim, cuda\n",
        "from torchsummary import summary\n",
        "import numpy as np\n",
        "from timeit import default_timer as timer\n",
        "import torch\n",
        "from torch.optim import lr_scheduler\n",
        "from PIL import Image\n",
        "\n",
        "import split_folders\n",
        "split_folders.fixed('train', output=\"datasplitted1\", seed=1337, fixed=(40, 40), oversample=False)\n",
        "\n",
        "new_colormin=(25,50,50)\n",
        "new_colormax=(80,255,255)\n",
        "\n",
        "def plot_mask(image, colormin, colormax):\n",
        "        hsv_p1 = cv2.cvtColor(image, cv2.COLOR_RGB2HSV)   \n",
        "        mask = cv2.inRange(hsv_p1, colormin , colormax)\n",
        "        result = cv2.bitwise_and(image, image, mask=mask)\n",
        "        #plt.figure(figsize=(15,10))\n",
        "        #plt.subplot(1, 3, 1)\n",
        "        #plt.imshow(image)\n",
        "        #plt.grid(False)\n",
        "        #plt.subplot(1, 3, 2)\n",
        "        #plt.imshow(mask, cmap=\"gray\")\n",
        "        #plt.grid(False)\n",
        "        #plt.subplot(1, 3, 3)\n",
        "        #plt.imshow(result)\n",
        "        #plt.grid(False)\n",
        "        return result\n",
        "\n",
        "def color_seg_rewrite(root_dir):\n",
        "    all_labels = listdir(path.join(root_dir))\n",
        "    all_data = []\n",
        "    \n",
        "    # Create a list of tuples out of data samples. Each tuple includes images file name and an int as label code\n",
        "\n",
        "    for label_code, parent_dir in enumerate(all_labels):\n",
        "        print(parent_dir)\n",
        "        parent_directory = path.join(root_dir, parent_dir)\n",
        "        file_list = listdir(parent_directory)\n",
        "        for file_name in file_list:\n",
        "            print(file_name)\n",
        "            img = cv2.imread(path.join(parent_directory, file_name))\n",
        "            \n",
        "            img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "            img = plot_mask(img, new_colormin, new_colormax)\n",
        "            \n",
        "            cv2.imwrite(path.join(parent_directory, file_name), img)\n",
        "color_seg_rewrite('datasplitted1/train')\n",
        "color_seg_rewrite('datasplitted1/test')\n",
        "color_seg_rewrite('datasplitted1/val')\n",
        "\n",
        "image_transforms = {\n",
        "    # Train uses data augmentation\n",
        "    'train':\n",
        "    transforms.Compose([\n",
        "        transforms.RandomResizedCrop(size=256, scale=(0.8, 1.0)),\n",
        "        transforms.RandomRotation(degrees=30),\n",
        "        transforms.ColorJitter(),\n",
        "        transforms.RandomHorizontalFlip(),\n",
        "        transforms.CenterCrop(size=224), \n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "    ]),\n",
        "    # Validation \n",
        "    'val':\n",
        "    transforms.Compose([\n",
        "        transforms.Resize(size=256),\n",
        "        transforms.CenterCrop(size=224),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "    ]),\n",
        "    # Test\n",
        "    'test':\n",
        "    transforms.Compose([\n",
        "        transforms.Resize(size=256),\n",
        "        transforms.CenterCrop(size=224),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "    ]),\n",
        "}\n",
        "\n",
        "batch_size = 16\n",
        "data = {\n",
        "    'train':\n",
        "    datasets.ImageFolder(root='datasplitted1/train', transform=image_transforms['train']),\n",
        "    'val':\n",
        "    datasets.ImageFolder(root='datasplitted1/val', transform=image_transforms['val']),\n",
        "    'test':\n",
        "    datasets.ImageFolder(root='datasplitted1/test', transform=image_transforms['test'])\n",
        "}\n",
        "\n",
        "# Dataloader iterators\n",
        "dataloaders = {\n",
        "    'train': DataLoader(data['train'], batch_size=batch_size, shuffle=True),\n",
        "    'val': DataLoader(data['val'], batch_size=batch_size, shuffle=True),\n",
        "    'test': DataLoader(data['test'], batch_size=batch_size, shuffle=True)\n",
        "}\n",
        "\n",
        "model = models.resnet152(pretrained=True)\n",
        "for param in model.parameters():\n",
        "    param.requires_grad = False\n",
        "\n",
        "n_class = len(data['train'].classes)\n",
        "num_ftrs = model.fc.in_features\n",
        "model.fc = nn.Sequential(\n",
        "            nn.Linear(num_ftrs, 256), nn.ReLU(), nn.Dropout(0.2),\n",
        "            nn.Linear(256, n_class), nn.LogSoftmax(dim=1))\n",
        "model = model.to('cuda')\n",
        "model.class_to_idx = data['train'].class_to_idx\n",
        "model.idx_to_class = {\n",
        "    idx: class_\n",
        "    for class_, idx in model.class_to_idx.items()\n",
        "}\n",
        "\n",
        "criterion = nn.NLLLoss()\n",
        "optimizer = optim.Adam(model.parameters())\n",
        "\n",
        "save_file_name = 'resnet152-transfer-1.pt'\n",
        "checkpoint_path = 'resnet152-transfer-1.pth'\n",
        "def train(model,\n",
        "          criterion,\n",
        "          optimizer,\n",
        "          scheduler,\n",
        "          train_loader,\n",
        "          valid_loader,\n",
        "          save_file_name,\n",
        "          max_epochs_stop=3,\n",
        "          n_epochs=30,\n",
        "          device='cuda'):\n",
        "   \n",
        "\n",
        "    valid_loss_min = np.Inf\n",
        "\n",
        "    valid_max_acc = 0\n",
        "    history = []\n",
        "\n",
        "    # Number of epochs already trained (if using loaded in model weights)\n",
        "    try:\n",
        "        print(f'Model has been trained for: {model.epochs} epochs.\\n')\n",
        "    except:\n",
        "        model.epochs = 0\n",
        "        print(f'Starting Training from Scratch.\\n')\n",
        "\n",
        "    overall_start = timer()\n",
        "\n",
        "    # Main loop\n",
        "    for epoch in range(n_epochs):\n",
        "\n",
        "        # keep track of training and validation loss each epoch\n",
        "        train_loss = 0.0\n",
        "        valid_loss = 0.0\n",
        "\n",
        "        train_acc = 0\n",
        "        valid_acc = 0\n",
        "\n",
        "        # Set to training\n",
        "        model.train()\n",
        "        start = timer()\n",
        "\n",
        "        # Iterate over data.\n",
        "        for ii, (data, target) in enumerate(train_loader):\n",
        "            model.train()\n",
        "            data, target = data.to(device), target.to(device)\n",
        "\n",
        "            # zero the parameter gradients\n",
        "            optimizer.zero_grad()\n",
        "            # forward\n",
        "            output = model(data)\n",
        "            _, pred = torch.max(output, dim=1)\n",
        "            loss = criterion(output, target)\n",
        "            \n",
        "            # backward\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            # stats\n",
        "            train_loss += loss.item() * data.size(0)\n",
        "            correct_tensor = pred.eq(target.data.view_as(pred))\n",
        "            accuracy = torch.mean(correct_tensor.type(torch.FloatTensor))\n",
        "            train_acc += accuracy.item() * data.size(0)\n",
        "\n",
        "            # Track training progress\n",
        "            print(\n",
        "                f'Epoch: {epoch}\\t{100 * (ii + 1) / len(train_loader):.2f}% complete. {timer() - start:.2f} seconds elapsed in epoch.',\n",
        "                end='\\r')\n",
        "\n",
        "        # After training loops ends, start validation\n",
        "        else:\n",
        "            model.epochs += 1\n",
        "            # Don't need to keep track of gradients\n",
        "            with torch.no_grad():\n",
        "                # Set to evaluation mode\n",
        "                model.eval()\n",
        "\n",
        "                # Validation loop\n",
        "                for data, target in valid_loader:\n",
        "                    # Tensors to gpu\n",
        "                    data, target = data.to(device), target.to(device)\n",
        "\n",
        "                    # Forward pass\n",
        "                    output = model(data)\n",
        "                    _, pred = torch.max(output, dim=1)\n",
        "                    loss = criterion(output, target)\n",
        "\n",
        "                    # stats\n",
        "                    valid_loss += loss.item() * data.size(0)\n",
        "                    correct_tensor = pred.eq(target.data.view_as(pred))\n",
        "                    accuracy = torch.mean(correct_tensor.type(torch.FloatTensor))\n",
        "                    valid_acc += accuracy.item() * data.size(0)\n",
        "\n",
        "                # Calculate average losses\n",
        "                train_loss = train_loss / len(train_loader.dataset)\n",
        "                valid_loss = valid_loss / len(valid_loader.dataset)\n",
        "\n",
        "                # Calculate average accuracy\n",
        "                train_acc = train_acc / len(train_loader.dataset)\n",
        "                valid_acc = valid_acc / len(valid_loader.dataset)\n",
        "\n",
        "                history.append([train_loss, valid_loss, train_acc, valid_acc])\n",
        "                scheduler.step()\n",
        "\n",
        "                \n",
        "                print(\n",
        "                    f'\\nEpoch: {epoch} \\tTraining Loss: {train_loss:.4f} \\tValidation Loss: {valid_loss:.4f}'\n",
        "                )\n",
        "                print(\n",
        "                    f'\\t\\tTraining Accuracy: {100 * train_acc:.2f}%\\t Validation Accuracy: {100 * valid_acc:.2f}%'\n",
        "                )\n",
        "\n",
        "                # Save the model if validation loss decreases\n",
        "                if valid_loss < valid_loss_min:\n",
        "                    # Save model\n",
        "                    torch.save(model.state_dict(), save_file_name)\n",
        "                    # Track improvement\n",
        "                    epochs_no_improve = 0\n",
        "                    valid_loss_min = valid_loss\n",
        "                    valid_best_acc = valid_acc\n",
        "                    best_epoch = epoch\n",
        "\n",
        "    # Attach the optimizer\n",
        "    model.optimizer = optimizer\n",
        "    # Record overall time and print out stats\n",
        "    total_time = timer() - overall_start\n",
        "    print(\n",
        "        f'\\nBest epoch: {best_epoch}, loss: {valid_loss_min:.2f}, accuracy: {100 * valid_acc:.2f}%'\n",
        "    )\n",
        "    print(\n",
        "        f'total training time(s){total_time:.2f}. Time per epoch{total_time / (epoch):.2f} seconds per epoch.'\n",
        "    )\n",
        "    # Format history\n",
        "    history = pd.DataFrame(\n",
        "        history,\n",
        "        columns=['train_loss', 'valid_loss', 'train_acc', 'valid_acc'])\n",
        "    return model, history\n",
        "\n",
        "train_on_gpu = True\n",
        "model, history = train(\n",
        "    model,\n",
        "    criterion,\n",
        "    optimizer,\n",
        "    dataloaders['train'],\n",
        "    dataloaders['val'],\n",
        "    save_file_name=save_file_name,\n",
        "    max_epochs_stop=5,\n",
        "    n_epochs=40)\n",
        "\n",
        "# plt.figure(figsize=(16, 12))\n",
        "fig, ax1 = plt.subplots()\n",
        "color = 'tab:red'\n",
        "for c in ['train_loss', 'valid_loss']:\n",
        "    ax1.plot(\n",
        "        history[c], label=c)\n",
        "ax1.set_xlabel('Epoch')\n",
        "ax1.set_ylabel('Average Cross Entropy')\n",
        "ax1.tick_params(axis='y', labelcolor=color)\n",
        "\n",
        "\n",
        "ax2 = ax1.twinx()\n",
        "color = 'tab:blue'\n",
        "# for c in ['train_acc', 'valid_acc']:\n",
        "ax2.plot(history['train_acc'], label='train_acc', color='r')\n",
        "ax2.plot(history['valid_acc'], label='valid_acc', color='g')\n",
        "ax2.set_ylabel('Average Accuracy')\n",
        "ax2.tick_params(axis='y', labelcolor=color)\n",
        "\n",
        "ax1.legend(loc = 10)\n",
        "ax2.legend(loc = 7)\n",
        "# plt.xlabel('Epoch')\n",
        "# plt.ylabel('Average Cross Entropy')\n",
        "plt.title('Training and Validation Losses & Accuracy')\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KVb7cglLnkt5"
      },
      "source": [
        "device = torch.device(\"cpu\")\n",
        "model = TinyModel().to(device)\n",
        "model.load_state_dict(torch.load('D:/507_plant_classification/model_save/1500_balance_bs64_e14_20.pt'), map_location=torch.device('cpu'))\n",
        "#torch.load('D:/507_plant_classification/model_save/1500_balance_bs64_e14_20.pt',map_location=torch.device('cpu'))\n",
        "nb_classes = 12\n",
        "model.eval() # model A\n",
        "\n",
        "confusion_matrix_A = torch.zeros(nb_classes, nb_classes)\n",
        "with torch.no_grad():\n",
        "    for i, (inputs, classes) in enumerate(test_loader2):\n",
        "        inputs = inputs.to(device)\n",
        "        classes = classes.to(device)\n",
        "        outputs = model(inputs)\n",
        "        _, preds = torch.max(outputs, 1)\n",
        "        for t, p in zip(classes.view(-1), preds.view(-1)):\n",
        "            confusion_matrix_A[t.long(), p.long()] += 1\n",
        "print(confusion_matrix_A)\n",
        "print(confusion_matrix_A.diag()/confusion_matrix_A.sum(1))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MbTTW3ovnkt_"
      },
      "source": [
        "pp = np.array(preds).tolist()\n",
        "index_both = [index for index in range(len(pp)) if pp[index] == 1 or pp[index] == 7]\n",
        "\n",
        "    \n",
        "model.eval() # model B\n",
        "correct = 0\n",
        "with torch.no_grad():\n",
        "    input_var = inputs[index_both]\n",
        "    target_var = classes[index_both]\n",
        "    output = model(input_var)\n",
        "    _, prediction = torch.max(output, 1)\n",
        "    correct = (target_var == prediction).sum().item()\n",
        "    accuracy = correct / input_var.shape[0]\n",
        "accuracy\n",
        "\n",
        "preds[index_both] = prediction"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zBPfZEGDnkuC"
      },
      "source": [
        "confusion_matrix_B = torch.zeros(nb_classes, nb_classes)\n",
        "\n",
        "for t, p in zip(classes.view(-1), preds.view(-1)):\n",
        "    confusion_matrix_B[t.long(), p.long()] += 1\n",
        "print(confusion_matrix_B)\n",
        "print(confusion_matrix_B.diag()/confusion_matrix_B.sum(1))\n",
        "\n",
        "\n",
        "from sklearn.metrics import f1_score, precision_score, recall_score\n",
        "f1 = f1_score(classes, preds, average='macro' )\n",
        "p = precision_score(classes, preds, average='macro')\n",
        "r = recall_score(classes, preds, average='macro')"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}